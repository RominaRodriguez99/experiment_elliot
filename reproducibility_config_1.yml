
experiment:
  dataset: movielens_1m
  data_config:
    strategy: dataset
    dataset_path: ../data/{0}/dataset.tsv
    # dataset assumes that the input data is NOT previously split in training, validation,
    #  and test set. For this reason, ONLY if we adopt a dataset strategy we can later perform 
    #  prefiltering and splitting operations.dataset takes just ONE default parameter: dataset_path, 
    #which points to the stored dataset.
  prefiltering:
    - strategy: global_threshold
      threshold: 4
      # global_threshold assumes a single system-wise threshold to filter out irrelevant transactions. 
      # global_threshold takes one mandatory parameter, threshold. threshold takes, as values, 
      # a float (ratings >= threshold will be kept), or the string average. 
      # With average, the system computes the global mean of the rating values and filters 
      # out all the ratings below.
    - strategy: iterative_k_core
      core: 10
      # iterative_k_core runs iteratively user_k_core:
      # user_k_core filters out all the users with a number of transactions lower 
      # than the given k core. It takes a parameter, core, where the user passes an int corresponding 
      # to the desired value., and item_k_core:
      # item_k_core filters out all the items with a number of transactions lower 
      # than the given k core. It takes a parameter, core, where the user passes an 
      # int corresponding to the desired value.
      #  until the dataset is no further modified. It takes a parameter, core, 
      #where the user passes an int corresponding to the desired value
      
  binarize: True
  splitting:
    save_on_disk: True
    save_folder: ../data/{0}/splitting/ #enables the writing process
    test_splitting:
      test_ratio: 0.2
      strategy: random_subsampling
      # random_subsampling generalizes random hold-out strategy. It takes a test_ratio parameter 
      # with a float value to define the train/test ratio for user-based hold-out splitting.
      #  Alternatively, it can take leave_n_out with an int value to define the number of
      #   transaction retained for the test set. Moreover, the splitting operation can be repeated 
      #   enabling the folds field and passing an int. In that case, the overall splitting strategy 
      #   corresponds to a user-based random subsampling strategy.
      folds:   5
  top_k: 50
  evaluation:
    cutoffs: [10, 20, 50]
    # es la longitud máxima de la lista de recomendaciones que queremos tener
    #  en cuenta al calcular la métrica (podría ser diferente de las k principales)

    simple_metrics: [nDCG, Recall, HR, Precision, MAP, MRR]
    # can be inserted as a field into the evaluation section, and it takes as a value the
    #  list of the metrics we want to compute
  gpu: 1
  #  the user enable GPU acceleration with Tensorflow
  external_models_path: ../external/models/__init__.py
  models:
    UserKNN: 
      meta:
        hyper_max_evals: 20
        #int field: where applicable, it defines the number of samples 
        #to consider for hyperparameter evaluation
        hyper_opt_alg: tpe
        #string field: it defines the hyperparameter tuning strategy
        save_recs: True
        verbose: True
      neighbors: [ uniform, 5, 1000 ]
      similarity: [cosine, jaccard, dice, mahalanobis, euclidean]
    ItemKNN: 
      meta:
        save_recs: True
        verbose: True
        hyper_max_evals: 20
        hyper_opt_alg: tpe
      neighbors: [uniform, 5, 1000]
      similarity: [cosine, jaccard, dice, pearson, euclidean]